{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kriging with external drift estimation on Jura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gstlearn.plot as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import minigst as mg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load the data set and the prediction grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the data and the prediction grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jura_all, grid, _ = mg.data(\"Jura\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the names of the Land Use and Rock in order to be consistent with their names on the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace landuse interger code by name\n",
    "landuse_codes=[1,2,3,4]\n",
    "landuse_names=[\"Forest\",\"Pasture\",\"Meadow\",\"Tillage\"]\n",
    "jura_all[\"Landuse\"]=jura_all[\"Landuse\"].replace(landuse_codes,landuse_names)\n",
    "\n",
    "## Replace rock type integer code by name\n",
    "rock_codes=[1,2,3,4,5]\n",
    "rock_names=[\"Argovian\",\"Kimmeridgian\",\"Sequanian\",\"Portlandian\",\"Quaternary\"]\n",
    "jura_all[\"Rock\"]=jura_all[\"Rock\"].replace(rock_codes,rock_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the predictor variables corresponding to Rock with one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# drop the first column for each feature\n",
    "enc = OneHotEncoder(handle_unknown='ignore',drop='first')\n",
    "enc.fit(jura_all[[\"Rock\"]])\n",
    "newnames = [\"Rock_K\",\"Rock_P\",\"Rock_Q\",\"Rock_S\"]\n",
    "rock_indic_jura = pd.DataFrame(enc.transform(jura_all[[\"Rock\"]]).toarray(),columns = newnames)\n",
    "jura_all = pd.concat([jura_all,rock_indic_jura],axis=1)\n",
    "rock_indic_grid = pd.DataFrame(enc.transform(grid[[\"Rock\"]]).toarray(),columns = newnames)\n",
    "grid = pd.concat([grid,rock_indic_grid],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data set in two sets : the training set and the validation set.\n",
    "For the project and the Kaggle competition, you should use the full data set for \n",
    "the training.\n",
    "You will submit your prediction on Kaggle for a set of locations on which you will \n",
    "only know the locations and the factors of Land Use and Rock at these locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntot = jura_all.shape[0]\n",
    "ntrain = 200\n",
    "nval = ntot - ntrain\n",
    "np.random.seed(123454)\n",
    "indtrain = np.random.choice(ntot,ntrain,replace=False).astype(int)\n",
    "indval = np.setdiff1d(np.arange(ntot),indtrain)\n",
    "\n",
    "jura =jura_all.loc[indtrain,:]\n",
    "\n",
    "#val contains the values to predict. For the project, these values will be on Kaggle\n",
    "#(for other locations) and you won't know them\n",
    "#You will have the locations and covariables at the unknown locations by the following command :\n",
    "val_loc =jura_all.loc[indval,['Xloc','Yloc'] + newnames]\n",
    "val=jura_all.loc[indval,['Co']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gstlearn objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a gstlearn database containing the data points, and assign the appropriate locators to the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Db\n",
    "db_jura=mg.df_to_db(jura, coord_names= [\"Xloc\",\"Yloc\"])\n",
    "db_jura.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a gstlearn *Grid Database* containing the target grid for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load grid data into  point database\n",
    "db_grid=mg.df_to_dbgrid(grid, coord_names= [\"Xloc\",\"Yloc\"])\n",
    "\n",
    "## Add selection to points with defined Rock type\n",
    "mg.add_sel(db_grid, ~np.isnan(db_grid[\"Rock_K\"]) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a Db containing the validation locations and the value of Cobalt concentrations at those locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Db\n",
    "db_val=mg.df_to_db(val_loc, coord_names= [\"Xloc\",\"Yloc\"])\n",
    "\n",
    "## Add Co values\n",
    "db_val[\"Co\"]=val\n",
    "\n",
    "db_val.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variography of the residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the variogram of the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create experimental variogram :\n",
    "## With - 30 lags separated by a distance 0.1 (meaning that we compute the variogram at lags h=0.1*i for i=0,...,30),\n",
    "## and consider a tolerance Ï„=50% on the distance\n",
    "\n",
    "#Vario of the residuals\n",
    "varioResiduals = mg.vario_exp(db_jura, vname= \"Co\", ext_drift= [\"Rock_*\"], nlag = 30, dlag = 0.1, toldis = 0.5)\n",
    "\n",
    "\n",
    "#Vario of the raw variable for comparison\n",
    "varioRaw = mg.vario_exp(db_jura, vname= \"Co\", nlag = 30, dlag = 0.1, toldis = 0.5)\n",
    "\n",
    "\n",
    "## Plot\n",
    "ax = gp.varmod(varioRaw,showPairs=False,label = \"Raw\")\n",
    "ax = gp.varmod(varioResiduals,showPairs=False,color = \"r\",label = \"Residual\")\n",
    "ax = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitmodRaw = mg.model_fit(varioRaw, struct = [\"NUGGET\",\"EXPONENTIAL\"])\n",
    "fitmodResiduals = mg.model_fit(varioResiduals, struct = [\"NUGGET\",\"EXPONENTIAL\"])\n",
    "\n",
    "## Plot\n",
    "gp.varmod(varioResiduals, fitmodResiduals)\n",
    "gp.varmod(varioRaw, fitmodRaw,color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kriging with external Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *kriging* function is called to perform the kriging with external drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove variables starting with a given prefix (-> Results from previous runs)\n",
    "mg.del_var_from_db(db_grid ,[\"KED*\"])\n",
    "mg.del_var_from_db(db_grid, [\"OK*\"])\n",
    "           \n",
    "## Compute kriging\n",
    "err = mg.minikriging(db_jura,db_grid, vname = \"Co\", ext_drift= [\"Rock_*\"], model = fitmodResiduals, prefix = \"KED\") \n",
    "\n",
    "## Compute ordinary kriging for comparison\n",
    "err = mg.minikriging(db_jura,db_grid, vname = \"Co\", model = fitmodRaw, prefix = \"OK\") \n",
    "\n",
    "## Display database\n",
    "db_grid.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot prediction\n",
    "im = gp.plot(db_grid, \"KED*estim\")\n",
    "gp.plot(db_jura, c='black')\n",
    "plt.title(\"Kriging with external Drift prediction\")\n",
    "plt.colorbar(im)\n",
    "plt.show()\n",
    "\n",
    "## Plot kriging standard-deviation\n",
    "im = gp.plot(db_grid, \"KED*stdev\")\n",
    "gp.plot(db_jura, c='black')\n",
    "plt.title(\"Kriging with external Drift standard-deviation\")\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask for the regression coefficients using *regression*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.regression(db_jura, \"Co\",  ext_drift = [\"Rock_*\"], model = fitmodRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the KED prediction at the validation locations and the resulting RMSE can then be done as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove variables starting with a given prefix (-> Results from previous runs)\n",
    "mg.del_var_from_db(db_val,[\"OK*\"])\n",
    "mg.del_var_from_db(db_val,[\"KED*\"])\n",
    "\n",
    "## Compute kriging\n",
    "err = mg.minikriging(db_jura,db_val, vname = \"Co\", ext_drift= [\"Rock_*\"], model = fitmodResiduals, prefix = \"KED\") \n",
    "\n",
    "## Compute ordinary kriging for comparison\n",
    "err = mg.minikriging(db_jura,db_val, vname = \"Co\", model = fitmodRaw, prefix = \"OK\") \n",
    "\n",
    "## Compute RMSE\n",
    "rmse_KED=np.mean((db_val[\"Co\"]-db_val[\"KED*estim\"])**2)**0.5\n",
    "rmse_OK=np.mean((db_val[\"Co\"]-db_val[\"OK*estim\"])**2)**0.5\n",
    "\n",
    "print(\"Ordinary Kriging RMSE\",rmse_OK)\n",
    "print(\"KED RMSE\",rmse_KED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1. Improve the model by adding other explanatory variables (e.g. Landuse or the interactions Rock*Landuse).\n",
    "2. Estimate the model parameters by maximum Likelihood.\n",
    "3. Define and adjust a multivariate model with drift. Compute the associated predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
